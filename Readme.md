## recencyQA  
**How Often Do Answers Change? Estimating Recency Requirements in Question Answering**  
SIGIR 2026

---

## ğŸ“Œ Overview

Large Language Models (LLMs) often answer time-sensitive questions using outdated knowledge. However, not all questions require the same level of freshness. Some answers change hourly, others yearly, and some never change at all.

**recencyQA** introduces a principled way to model this temporal behavior.

We propose a **Recencyâ€“Stationarity Taxonomy** and release **recencyQA**, the first dataset that explicitly annotates:

- âœ… Expected answer update frequency (**Recency**)  
- âœ… Context stability of that frequency (**Stationarity**)  
- âœ… Verified temporal contexts inducing different recency interpretations  

This enables fine-grained evaluation of temporal awareness in QA systems beyond binary "fresh vs outdated" distinctions.

---

## ğŸ§  Recencyâ€“Stationarity Taxonomy

We characterize temporal sensitivity along **two orthogonal dimensions**:

### 1ï¸âƒ£ Recency (Expected Time Until Answer Changes)

12 discrete classes ranging from highly volatile to permanent:

| Class | Expected Change |
|-------|-----------------|
| An-Hour | Within an hour |
| A-Few-Hours | Within a few hours |
| A-Day | Within a day |
| A-Few-Days | Within a few days |
| A-Week | Within a week |
| A-Few-Weeks | Within a few weeks |
| A-Month | Within a month |
| A-Few-Months | Within a few months |
| A-Year | Within a year |
| A-Few-Years | Within a few years |
| Many-Years | After many years |
| Never | Not expected to change |

---

### 2ï¸âƒ£ Stationarity

- **Stationary** â†’ Recency class remains stable over time  
- **Non-Stationary** â†’ Recency class depends on context  

Example:

- *Who is the CEO of X?* â†’ Typically stationary  
- *Who is leading the Olympic medal table?* â†’ Non-stationary  

---

## ğŸ“Š Dataset Statistics

After verification and filtering:

- **4,031 questions**
- **12 recency classes**
- **2,910 stationary questions**
- **1,121 non-stationary questions**
- Average question length: 14.26 words
- Average context length: 22.22 words

Each question includes:

- 13 recency samples  
- Majority recency label  
- Full recency distribution  
- Stationarity label  
- Verified temporal context  
- Structured JSON format  

---

## ğŸ“‚ Dataset Access

The dataset is available in the `Dataset` folder:

ğŸ“ **[Dataset/RecencyQA](./Dataset/RecencyQA.json)**

The dataset includes:

- Full dataset (.json)
- Train / Validation / Test splits (if applicable)
- Prompt templates used in experiments
- Context generation prompts

---

## ğŸ“ Dataset Format

Each JSON entry follows this structure:



---

## ğŸ”¬ What recencyQA Evaluates

recencyQA supports three levels of temporal evaluation:

### 1ï¸âƒ£ Recency Classification
Can a model infer how often an answer changes from the question alone?

### 2ï¸âƒ£ Context Sensitivity
Does adding temporal context improve performance â€” especially for non-stationary questions?

### 3ï¸âƒ£ Recency Transition (RL1 â†’ RL2)
Can a model adapt when the same question requires different recency labels under different contexts?

---

## ğŸ“ˆ Key Findings

From experiments across multiple LLMs:

- Fine-grained recency classification is difficult (24â€“52% strict accuracy)
- Tolerant accuracy is significantly higher â†’ models capture coarse temporal ordering
- Context improves performance for non-stationary questions (up to +40%)
- Context can harm performance for stationary questions
- Transition accuracy remains very low â†’ models struggle with dynamic adaptation

**Conclusion:**  
Current LLMs exhibit largely static temporal reasoning.

---

## ğŸ— Dataset Construction Pipeline

### 1ï¸âƒ£ Question Collection
- FreshQA  
- PATQA  
- SituatedQA  
- LLaMA 3.3-generated event-based questions  

### 2ï¸âƒ£ Recency Labeling
- 13 independent samples per question  
- Majority voting  
- Recency distribution retained  

### 3ï¸âƒ£ Stationarity Classification
- GPT-5.2  
- Gemini 3 Flash  
- Claude Sonnet 4.5  
- Cross-validation with recency distribution  

### 4ï¸âƒ£ Context Generation
- Contexts generated to induce specific recency labels  
- Verified via 13 re-classification runs  
- Only strictly consistent contexts retained  

---

## ğŸš€ Research Applications

recencyQA enables research on:

- Recency-aware QA  
- Retrieval-augmented generation (RAG) triggering  
- Temporal confidence calibration  
- Freshness-sensitive ranking  
- Temporal drift analysis  
- Dynamic multi-hop reasoning  
- Recency-based retrieval gating  

---

## ğŸ“œ Citation

If you use recencyQA, please cite:

```Comming Soon
```

---

## ğŸ“„ Paper

Paper PDF:

```
Comming Soon
```

---

## ğŸ“œ License

Creative Commons Attribution 4.0 International License (CC BY 4.0)

---

## ğŸ¤ Contact

For questions, collaborations, or issues:

- Bhawna Piryani â€“ bhawna.piryani@uibk.ac.at  
- Zehra Mertz â€“ mertz@mef.edu.tr  
- Adam Jatowt â€“ adam.jatowt@uibk.ac.at  

---
